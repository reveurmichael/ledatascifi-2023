{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers to Pandas Exercises\n",
    "\n",
    "There are many ways to solve each of these!\n",
    "\n",
    "Run each cell below in little incremental bits to really see how the code blocks work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr # IF NECESSARY, from terminal: pip install pandas_datareader \n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "start = datetime.datetime(2017, 1, 1) # you can specify start and end dates this way\n",
    "end = datetime.datetime(2021, 1, 27)\n",
    "macro_df = pdr.data.DataReader(['GDP','CPIAUCSL','UNRATE'], 'fred', start, end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "During class, I used this dataframe to go over [Pandas vocab](02b_pandasVocab), and we show how to\n",
    "- access 1 variable (note: `pd` calls this a \"series\" object, which is a 1D object instead of a 2D object)\n",
    "- access multiple vars\n",
    "- access, print, and change column names\n",
    "- access, print, reset, and set the index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "- Q0: Do each of the four new golden rules for initial data exploration, from the lecture.\n",
    "- Q1: What is the second series above?\n",
    "- Q2: What is the frequency of the series?\n",
    "- Q3: What is the average ANNUAL GDP, based on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  GDP  CPIAUCSL  UNRATE\n",
      "DATE                                   \n",
      "2017-01-01  19153.912   243.620     4.7\n",
      "2017-02-01        NaN   243.872     4.6\n",
      "2017-03-01        NaN   243.766     4.4\n",
      "2017-04-01  19322.920   244.274     4.5\n",
      "2017-05-01        NaN   244.069     4.4 \n",
      "---\n",
      "                  GDP  CPIAUCSL  UNRATE\n",
      "DATE                                   \n",
      "2020-09-01        NaN   260.149     7.8\n",
      "2020-10-01  21477.597   260.462     6.9\n",
      "2020-11-01        NaN   260.927     6.7\n",
      "2020-12-01        NaN   261.560     6.7\n",
      "2021-01-01  22038.226   262.231     6.3 \n",
      "---\n",
      "Index(['GDP', 'CPIAUCSL', 'UNRATE'], dtype='object') \n",
      "---\n",
      "The shape is:  (49, 3) \n",
      "---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 49 entries, 2017-01-01 to 2021-01-01\n",
      "Freq: MS\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   GDP       17 non-null     float64\n",
      " 1   CPIAUCSL  49 non-null     float64\n",
      " 2   UNRATE    49 non-null     float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 1.5 KB\n",
      "Info: None \n",
      "---\n",
      "                GDP    CPIAUCSL     UNRATE\n",
      "count     17.000000   49.000000  49.000000\n",
      "mean   20654.744824  252.878469   5.034694\n",
      "std      913.690696    5.557894   2.524179\n",
      "min    19153.912000  243.620000   3.500000\n",
      "25%    19882.965000  248.721000   3.800000\n",
      "50%    20813.325000  252.899000   4.000000\n",
      "75%    21477.597000  257.387000   4.500000\n",
      "max    22038.226000  262.231000  14.800000 \n",
      "---\n",
      "UNRATE has 22 values and its top 10 most common are:\n",
      "3.8    7\n",
      "3.6    5\n",
      "4.0    5\n",
      "4.4    4\n",
      "3.7    4\n",
      "4.1    3\n",
      "3.5    3\n",
      "6.7    2\n",
      "4.3    2\n",
      "4.2    2\n",
      "Name: UNRATE, dtype: int64 \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# do your work here\n",
    "def insufficient_but_starting_eda(df,cat_vars_list=None):\n",
    "    '''\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DATAFRAME\n",
    "    cat_vars_list : LIST, optional\n",
    "        A list of strings containing variable names in the dataframe\n",
    "        for variables where you want to see the number of unique values\n",
    "        and the 10 most common values. Likely used for categorical values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None. It simply prints.\n",
    "    \n",
    "    Description\n",
    "    -------    \n",
    "    This function will print a MINIMUM amount of info about a new dataframe. \n",
    "    \n",
    "    You should ****look**** at all this output below and consider the data\n",
    "    exploration and cleaning questions from \n",
    "    https://ledatascifi.github.io/ledatascifi-2023/content/03/02e_eda_golden.html#member\n",
    "    \n",
    "    Also LOOK at more of the data manually. \n",
    "    \n",
    "    Then write up anything notable you observe.\n",
    "    \n",
    "    TIP: put this function in your codebook to reuse easily.\n",
    "    \n",
    "    PROTIP: Improve this function (better outputs, better formatting).\n",
    "    \n",
    "    FEATURE REQUEST: optionally print the nunique and top 10 values under the describe matrix\n",
    "    \n",
    "    FEATURE REQUEST: optionally print more stats (percentiles)\n",
    "    \n",
    "    '''\n",
    "    print(df.head(),  '\\n---')\n",
    "    print(df.tail(),  '\\n---')\n",
    "    print(df.columns, '\\n---')\n",
    "    print(\"The shape is: \",df.shape, '\\n---')\n",
    "    print(\"Info:\",df.info(), '\\n---') # memory usage, name, dtype, and # of non-null obs (--> # of missing obs) per variable\n",
    "    print(df.describe(), '\\n---') # summary stats, and you can customize the list!\n",
    "    if cat_vars_list != None:\n",
    "        for var in cat_vars_list:\n",
    "            print(var,\"has\",df[var].nunique(),\"values and its top 10 most common are:\")\n",
    "            print(df[var].value_counts().head(10), '\\n---')\n",
    "        \n",
    "insufficient_but_starting_eda(macro_df,['UNRATE'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some answers\n",
    "- Q0: What have we learned about the data? Anything to keep track of? (GDP is annual, others are quarterly)\n",
    "- Q1: Inflation (CPI)\n",
    "- Q2: Quarterly, but GDP is only annual\n",
    "- Q3: 20,630 (trillion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "- Q4: Download the annual *real* gdp from 1960 to 2018 from FRED and compute the average annual percent change\n",
    "- Q5: Compute the average gdp percent change within *each decade*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03067733411159815"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do your work here\n",
    "\n",
    "# v1:\n",
    "part2_df = pdr.data.DataReader(['GDPCA'], 'fred', 1960, 2018) \n",
    "part2_df['real_gdp_pct'] = part2_df['GDPCA'].pct_change()\n",
    "part2_df['real_gdp_pct'].mean()\n",
    "\n",
    "# prof notes: after students present, go through, bit by bit\n",
    "# then add comments (a la psuedo), \n",
    "# reiter access var: df[var], how methods apply to obj df[var].func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03067733411159815"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1.1: chain the last 2 lines together\n",
    "part2_df = pdr.data.DataReader(['GDPCA'], 'fred', 1960, 2018) \n",
    "part2_df['GDPCA'].pct_change().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GDPCA    0.030677\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v1.2 that last line could be:    \n",
    "(part2_df\n",
    "     .pct_change()\n",
    "     .mean()\n",
    "     \n",
    ")\n",
    "\n",
    "# explain reasons for chaining: readable, no temp objects\n",
    "\n",
    "# breaking this up into 3 lines is silly but shows chaining over multiple lines\n",
    "# how can we add the first line (the DL) into this? (next block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03067733411159815"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2.0: chaining - but involves a lambda function work around\n",
    "# don't cover until we go over lambdas\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    \n",
    "    # create the var\n",
    "    # syntax is: .assign(newname = fcn(df(var)))\n",
    "    # try this:\n",
    "    #.assign(sillyvar=1)\n",
    "    # but this df doesn't have a name! how do we access it?\n",
    "    # trick: \"lambda\" function. \n",
    "    #        here x is the object that assign is working on,\n",
    "    #        meaning what ever is produced right before .assign\n",
    "    #        which is just the **df** we DLed on the line above\n",
    "    #\n",
    "    # this is VERY COMMON in pandas chaining:\n",
    "    # .assign(newvarname = lambda <tempnameforpriorobj>:  <do stuff to tempnameforpriorobj>   )       \n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    \n",
    "    # grab the var and take its mean\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03067733411159815"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v2.1: chaining - clean\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    # create var\n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    # get mean value\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decade\n",
       "1960.0    0.047426\n",
       "1970.0    0.032352\n",
       "1980.0    0.031240\n",
       "1990.0    0.032261\n",
       "2000.0    0.019175\n",
       "2010.0    0.022464\n",
       "Name: real_gdp_pct, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5:\n",
    "import numpy as np\n",
    "# v2.1: chaining - clean\n",
    "(\n",
    "    # DL data\n",
    "    pdr.data.DataReader(['GDPCA','GDPA'], 'fred', 1960, 2018) \n",
    "    # create var pct change\n",
    "    .assign(real_gdp_pct = lambda x: x['GDPCA'].pct_change())\n",
    "    # get the decade from the index (do this BIT BY BIT)\n",
    "    .reset_index() # turn it into variable\n",
    "        # how to pull year out of date?\n",
    "        # DATE is a datetime series. dt is a way to access properities of the date \n",
    "    .assign(decade = lambda x: np.floor(x.DATE.dt.year/10)*10)\n",
    "    # for each decade = groupby!\n",
    "    .groupby('decade')\n",
    "    # take mean\n",
    "    ['real_gdp_pct'].mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "First, I'll load January data on unemployment, the Case-Shiller housing index, and median household income in three states (CA/MI/PA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " DATA BEFORE FORMATTING: \n",
      "\n",
      "\n",
      "      CAUR  MIUR  PAUR      LXXRSA      DEXRSA      WDXRSA  MEHOINUSCAA672N  \\\n",
      "DATE                                                                          \n",
      "1990   5.2   7.7   5.2  100.471193         NaN   93.362855          64124.0   \n",
      "1991   7.1   8.8   6.5   95.569015   58.420806   89.706871          62568.0   \n",
      "1992   8.6   9.5   7.4   92.786926   59.748947   88.573807          63297.0   \n",
      "1993   9.8   7.6   7.2   85.246295   61.564205   89.065118          60272.0   \n",
      "1994   9.3   7.2   6.7   77.395052   64.526663   88.988467          61219.0   \n",
      "1995   7.8   5.2   5.7   76.376389   68.973289   89.670303          62618.0   \n",
      "1996   7.8   4.9   5.9   73.919989   73.582339   88.655369          63965.0   \n",
      "1997   6.9   4.7   5.3   74.536884   79.347642   88.775224          64035.0   \n",
      "1998   6.0   4.0   4.8   81.035037   85.183613   90.108149          65153.0   \n",
      "1999   5.6   4.0   4.5   92.140086   92.433567   94.188054          67994.0   \n",
      "2000   5.0   3.3   4.2  101.031209  100.145625  100.871832          70566.0   \n",
      "2001   4.8   4.4   4.3  112.031476  107.327208  113.794411          69267.0   \n",
      "2002   6.6   6.3   5.5  122.706507  111.468549  127.245701          68444.0   \n",
      "2003   6.9   6.5   5.8  145.752401  115.704198  146.676851          69553.0   \n",
      "2004   6.6   6.7   5.4  178.773750  119.772720  169.535303          67616.0   \n",
      "2005   5.8   7.2   5.2  221.471348  123.264823  210.799935          68766.0   \n",
      "2006   5.0   6.8   4.8  268.208801  126.872677  250.272523          71194.0   \n",
      "2007   4.9   7.0   4.4  270.804836  118.163888  241.411114          69750.0   \n",
      "2008   5.9   7.2   4.8  226.111844  100.378575  215.656550          68712.0   \n",
      "2009   9.9  10.9   7.0  167.831065   77.690839  174.183883          67888.0   \n",
      "\n",
      "      MEHOINUSMIA672N  MEHOINUSPAA672N  \n",
      "DATE                                    \n",
      "1990          57665.0          55870.0  \n",
      "1991          59693.0          56440.0  \n",
      "1992          58517.0          54191.0  \n",
      "1993          57776.0          54827.0  \n",
      "1994          61138.0          55562.0  \n",
      "1995          61632.0          58413.0  \n",
      "1996          64646.0          57516.0  \n",
      "1997          62499.0          60523.0  \n",
      "1998          66564.0          62098.0  \n",
      "1999          71828.0          58844.0  \n",
      "2000          68601.0          63573.0  \n",
      "2001          66020.0          63752.0  \n",
      "2002          61631.0          61318.0  \n",
      "2003          63517.0          60570.0  \n",
      "2004          58047.0          60588.0  \n",
      "2005          61031.0          61518.0  \n",
      "2006          62607.0          62388.0  \n",
      "2007          61785.0          60618.0  \n",
      "2008          60004.0          61949.0  \n",
      "2009          55625.0          58259.0  \n",
      "\n",
      "\n",
      " DATA AFTER FORMATTING: \n",
      "\n",
      "\n",
      "     Unemployment               HouseIdx                         MedIncome  \\\n",
      "               CA    MI   PA          CA          MI          PA        CA   \n",
      "DATE                                                                         \n",
      "1990          5.2   7.7  5.2  100.471193         NaN   93.362855   64124.0   \n",
      "1991          7.1   8.8  6.5   95.569015   58.420806   89.706871   62568.0   \n",
      "1992          8.6   9.5  7.4   92.786926   59.748947   88.573807   63297.0   \n",
      "1993          9.8   7.6  7.2   85.246295   61.564205   89.065118   60272.0   \n",
      "1994          9.3   7.2  6.7   77.395052   64.526663   88.988467   61219.0   \n",
      "1995          7.8   5.2  5.7   76.376389   68.973289   89.670303   62618.0   \n",
      "1996          7.8   4.9  5.9   73.919989   73.582339   88.655369   63965.0   \n",
      "1997          6.9   4.7  5.3   74.536884   79.347642   88.775224   64035.0   \n",
      "1998          6.0   4.0  4.8   81.035037   85.183613   90.108149   65153.0   \n",
      "1999          5.6   4.0  4.5   92.140086   92.433567   94.188054   67994.0   \n",
      "2000          5.0   3.3  4.2  101.031209  100.145625  100.871832   70566.0   \n",
      "2001          4.8   4.4  4.3  112.031476  107.327208  113.794411   69267.0   \n",
      "2002          6.6   6.3  5.5  122.706507  111.468549  127.245701   68444.0   \n",
      "2003          6.9   6.5  5.8  145.752401  115.704198  146.676851   69553.0   \n",
      "2004          6.6   6.7  5.4  178.773750  119.772720  169.535303   67616.0   \n",
      "2005          5.8   7.2  5.2  221.471348  123.264823  210.799935   68766.0   \n",
      "2006          5.0   6.8  4.8  268.208801  126.872677  250.272523   71194.0   \n",
      "2007          4.9   7.0  4.4  270.804836  118.163888  241.411114   69750.0   \n",
      "2008          5.9   7.2  4.8  226.111844  100.378575  215.656550   68712.0   \n",
      "2009          9.9  10.9  7.0  167.831065   77.690839  174.183883   67888.0   \n",
      "\n",
      "                        \n",
      "           MI       PA  \n",
      "DATE                    \n",
      "1990  57665.0  55870.0  \n",
      "1991  59693.0  56440.0  \n",
      "1992  58517.0  54191.0  \n",
      "1993  57776.0  54827.0  \n",
      "1994  61138.0  55562.0  \n",
      "1995  61632.0  58413.0  \n",
      "1996  64646.0  57516.0  \n",
      "1997  62499.0  60523.0  \n",
      "1998  66564.0  62098.0  \n",
      "1999  71828.0  58844.0  \n",
      "2000  68601.0  63573.0  \n",
      "2001  66020.0  63752.0  \n",
      "2002  61631.0  61318.0  \n",
      "2003  63517.0  60570.0  \n",
      "2004  58047.0  60588.0  \n",
      "2005  61031.0  61518.0  \n",
      "2006  62607.0  62388.0  \n",
      "2007  61785.0  60618.0  \n",
      "2008  60004.0  61949.0  \n",
      "2009  55625.0  58259.0  \n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA AND CONVERT TO ANNUAL\n",
    "\n",
    "start = 1990 # pandas datareader can infer these are years\n",
    "end = 2018\n",
    "macro_data = pdr.data.DataReader(['CAUR','MIUR','PAUR', # unemployment \n",
    "                                  'LXXRSA','DEXRSA','WDXRSA', # case shiller index in LA, Detroit, DC (no PA  available!)\n",
    "                                  'MEHOINUSCAA672N','MEHOINUSMIA672N','MEHOINUSPAA672N'], #  \n",
    "                                 'fred', start, end)\n",
    "macro_data = macro_data.resample('Y').first() # get's the first observation for each variable in a given year\n",
    "\n",
    "# CLEAN UP THE FORMATING SOMEWHAT\n",
    "\n",
    "macro_data.index = macro_data.index.year\n",
    "print(\"\\n\\n DATA BEFORE FORMATTING: \\n\\n\")\n",
    "print(macro_data[:20]) # see how the data looks now? ugly variable names, but its an annual dataset at least\n",
    "macro_data.columns=pd.MultiIndex.from_tuples([\n",
    "    ('Unemployment','CA'),('Unemployment','MI'),('Unemployment','PA'),\n",
    "    ('HouseIdx','CA'),('HouseIdx','MI'),('HouseIdx','PA'),\n",
    "    ('MedIncome','CA'),('MedIncome','MI'),('MedIncome','PA')\n",
    "    ])\n",
    "print(\"\\n\\n DATA AFTER FORMATTING: \\n\\n\")\n",
    "print(macro_data[:20]) # this is a dataset that is \"wide\", and now \n",
    "                       # the column variable names have 2 levels - var name, \n",
    "                       # and unit/state that variable applies to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q6: for each decade and state, report the average annual CHANGE (level, not percent) in unemployment\n",
    "- Q7: for each decade and state, report the average annual PERCENT CHANGE in house prices and household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do your work here: \n",
    "\n",
    "# let's pseudocode\n",
    "\n",
    "# q6 \n",
    "# get decade variable\n",
    "# get annual change/difference (level) in unemploy for each state\n",
    "# average unemploy for each state within decade\n",
    "\n",
    "# q7\n",
    "# get decade variable\n",
    "# get annual pct change in house price and income for each state\n",
    "# average those for each state within decade\n",
    "\n",
    "# HEY! those are similar - let's combine:\n",
    "\n",
    "# get decade variable\n",
    "# get annual change in unemploy for each state\n",
    "# get annual pct change in house price and income for each state\n",
    "# average unemploy for each state within decade\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error easter-egg hunt\n",
    "\n",
    "This code is _allllllllmost_ correct. It actually generates incorrect answers. If you figure out the problem and/or the solution, please submit an error fix via the \"edit\" button at the top of this page. ",
    "\n",
    "HINT: [ABCD](../02/10_Golden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">HouseIdx_pctch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">MedIncome_pctch</th>\n",
       "      <th colspan=\"3\" halign=\"left\">unemploy_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "      <th>CA</th>\n",
       "      <th>MI</th>\n",
       "      <th>PA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>-0.71</td>\n",
       "      <td>-3.13</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>4.44</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>7.52</td>\n",
       "      <td>-1.20</td>\n",
       "      <td>7.22</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-2.42</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>43.00</td>\n",
       "      <td>69.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>5.84</td>\n",
       "      <td>5.15</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.54</td>\n",
       "      <td>-61.11</td>\n",
       "      <td>-71.11</td>\n",
       "      <td>-24.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       HouseIdx_pctch             MedIncome_pctch             unemploy_diff  \\\n",
       "state              CA    MI    PA              CA    MI    PA            CA   \n",
       "decade                                                                        \n",
       "1990            -0.71 -3.13 -2.06            0.69  0.22 -0.46          4.44   \n",
       "2000             7.52 -1.20  7.22            0.01 -2.42 -0.03         43.00   \n",
       "2010             5.84  5.15  2.82            0.84  1.42  1.54        -61.11   \n",
       "\n",
       "                      \n",
       "state      MI     PA  \n",
       "decade                \n",
       "1990    -4.00   0.00  \n",
       "2000    69.00  25.00  \n",
       "2010   -71.11 -24.44  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "(\n",
    "    # reformat the data to tall:\n",
    "    macro_data.stack().swaplevel().sort_index().reset_index().rename(columns={'level_0':'state'})\n",
    "    \n",
    "    # create vars <---- this is not even needed to explain this block!\n",
    "    .assign(\n",
    "            decade          = lambda x: 10*np.floor(x['DATE']/10).astype(int),\n",
    "            unemploy_diff   = lambda x: x['Unemployment'].diff(),\n",
    "            HouseIdx_pctch  = lambda x: x['HouseIdx'].pct_change(),\n",
    "            MedIncome_pctch = lambda x: x['MedIncome'].pct_change()    \n",
    "    )\n",
    "    \n",
    "    # opt A for output:\n",
    "    .pivot_table(index='decade',\n",
    "                 columns='state',\n",
    "                 values=['unemploy_diff','HouseIdx_pctch','MedIncome_pctch'])\n",
    "    .multiply(100) # for more meaningful displays \n",
    "    \n",
    "    # opt B for output + formatting (here, as percentages)\n",
    "#     .groupby(['state','decade'])\n",
    "#     [['unemploy_diff','HouseIdx_pctch','MedIncome_pctch']].mean()\n",
    "#     .multiply(100)\n",
    "#     # note about this: unemp isn't a % diff, but a p.p \n",
    "#     # so I make it explicit \n",
    "#     .style.format({'HouseIdx_pctch': '{0:,.2f}%',\n",
    "#                    'MedIncome_pctch': '{0:,.2f}%',\n",
    "#                    'unemploy_diff': '{0:,.2f} p.p.'}) \n",
    "    \n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
