{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS FILE IS IN THE HANDOUTS FOLDER. COPY IT INTO YOUR CLASS NOTES\n",
    "\n",
    "- [**Read the chapter on the website!**](https://ledatascifi.github.io/ledatascifi-2022/content/05/02_reg.html) It contains a lot of extra information we won't cover in class extensively.\n",
    "- After reading that, I recommend [this webpage as a complimentary place to get additional intuition.](https://aeturrell.github.io/coding-for-economists/econmt-regression.html)\n",
    "\n",
    "## ASAP\n",
    "\n",
    "[Declare your team and project interests in the project sheet](https://docs.google.com/spreadsheets/d/1A6oQfhTBHHEb_EWSgfQv2KgsBoZm4V_BQWuvTjxnrdo/edit#gid=1508330834)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today: Regression\n",
    "\n",
    "We start our machine learning applications with regression for a few simple reasons:\n",
    "- Regression is fundamental method for estimating the relationship between a variable (\"y\") that condition on many (\"X\") variables. \n",
    "- But the coefficients obtained can also be used to generate predictions. \n",
    "- _Note: The focus in this section is on RELATIONSHIP paradigm_\n",
    "- Many issues that confront researchers have well understood solutions when regression is the model being used. \n",
    "- Regression coefficients are easy to interpret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "## Objectives\n",
    "\n",
    "1. You can fit a regression with `statsmodels` or `sklearn`\n",
    "    - statsmodels: Nicer result tables, usually easier to specifying the regression model\n",
    "    - sklearn: Easier to use within a prediction/ML exercise\n",
    "2. You can view the results visually or numerically of your model with either method\n",
    "3. The focus today is on the _mechanics_ of running regressions, viewing the output, and using the estimation's output objects.\n",
    "\n",
    "![](https://media.giphy.com/media/yoJC2K6rCzwNY2EngA/giphy.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.formula.api import ols as sm_ols\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First, we load the data. \n",
    "\n",
    "**This is a new dataset, so we should do some data exploration!** Things students should try:\n",
    "- describe() - any impossible values\n",
    "- value_count() any categorical variables\n",
    "- didn't we have a community function to start the EDA?\n",
    "- correlation heat map\n",
    "- look for outliers for all variables, and within pairplots\n",
    "- print out and explore many sections of the data manually (in Excel or Spyder) to get familiar and check for data consistency issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/LeDataSciFi/ledatascifi-2022/blob/main/data/Fannie_Mae_Plus_Data.gzip?raw=true'\n",
    "fannie_mae = pd.read_csv(url,compression='gzip') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "Spend 5 minutes exploring the data and jot down what you learn about the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean the data and create variables we will use\n",
    "\n",
    "These variables are pretty straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fannie_mae = (fannie_mae\n",
    "                  # create variables\n",
    "                  .assign(l_credscore = np.log(fannie_mae['Borrower_Credit_Score_at_Origination']),\n",
    "                          l_LTV = np.log(fannie_mae['Original_LTV_(OLTV)']),\n",
    "                          Origination_Date = lambda x: pd.to_datetime(x['Origination_Date']),\n",
    "                          Origination_Year = lambda x: x['Origination_Date'].dt.year,\n",
    "                          const = 1,\n",
    "                          great = fannie_mae['Borrower_Credit_Score_at_Origination'] >= 800\n",
    "                         )\n",
    "              \n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit rating is a number between 0 and 850. But in some analysis, it might make sense to have categories of credit ratings (e.g. bad to good). I borrowed [these cutoffs from experian.](https://www.experian.com/blogs/ask-experian/infographic-what-are-the-different-scoring-ranges/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a categorical bin var with \"pd.cut()\"\n",
    "\n",
    "fannie_mae['creditbins']= pd.cut(fannie_mae['Borrower_Credit_Score_at_Origination'],\n",
    "                                 [0,579,669,739,799,850],\n",
    "                                 labels=['Very Poor','Fair','Good','Very Good','Exceptional'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the variable that created. I notice that 669 (right on the threshold of a bin) goes into the \"Fair\" bin instead of \"Good\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fannie_mae.loc[:5,['Borrower_Credit_Score_at_Origination','creditbins']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.cut took credit , var number between 0 and 850,\n",
    "# and changed it to bins. I labeled the bins explicitly\n",
    "\n",
    "fannie_mae['creditbins'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises with statsmodels\n",
    "\n",
    "- **For all problems: y is the interest rate of the loan**\n",
    "- I recommend the _statsmodels formula_ method on the website\n",
    "\n",
    "Psuedocode for using statsmodels to run a regression:\n",
    "```python\n",
    "model = sm_ols(<formula>, data=<dataframe>)\n",
    "result=model.fit()\n",
    "\n",
    "# to print regression output: result.summary()\n",
    "# get predicted values (yhat): result.predict\n",
    "# get regression residuals (uhat): result.resid\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: Starter regressions\n",
    "\n",
    "A. Regress y on the credit score (student demo): $y=\\beta_0 + \\beta_1*\\text{Credit Score}$\n",
    "- _I'll show 2 ways: the psuedo code and the one-liner_\n",
    "\n",
    "B. Regress y on the **natural log** of the credit score: $y=\\beta_0 + \\beta_1*log(\\text{Credit Score})$\n",
    "- _I'll show two ways to do this_\n",
    "\n",
    "C. Regress y on the **natural log** of the loan-to-value\n",
    "\n",
    "D. Regress y on the natural log of the loan-to-value and the natural log of the credit score: $y=\\beta_0 + \\beta_1*log(\\text{LTV}) + \\beta_2*log(\\text{Credit Score})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Best practices: Look at the outputs every time\n",
    "\n",
    "Let's talk about the outputs you see and should look at EVERY time you run a regression:\n",
    "- Number of obs\n",
    "- R2 \n",
    "- AR2\n",
    "- Coef \n",
    "- Std error, t value, p value (\"P>|t|\")\n",
    "- Std error options:\n",
    "    - `.fit(cov_type=\"HC2\")`\n",
    "    - `.fit(cov_type=\"cluster\", cov_kwds={\"groups\": df[\"industry\"]})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: Regressions with transformations\n",
    "\n",
    "We are talking about \"linear regression. What that means is that the model is linear in the regressors: but it doesnâ€™t mean that those regressors can't be some kind of non-linear transform of the original features $x_i$.\" The most common transformations are logging variables, interaction terms, and polynomial terms.\"\n",
    "\n",
    "We already did log transformations above. \n",
    "\n",
    "An interaction term simply means one regressor is two variables multiplied:\n",
    "- $y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_1 x_2$\n",
    "- $y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 $\n",
    "\n",
    "Polynomial terms might look like:\n",
    "- $y=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_1^2$\n",
    "\n",
    "A. Regress y on the credit score and the credit score squared. \n",
    "\n",
    "B. Regress y on the natural log of the loan-to-value, the natural log of the credit score, and the interaction of LTV and credit score. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: Dummy and categorical variables\n",
    "\n",
    "A. Regress y on the dummy variable for a great credit score.\n",
    "\n",
    "B. Regress y on the categorical variable we created for credit bins.\n",
    "\n",
    "C. (Advanced, optional, after class exercise): High dimensional fixed effects. This basically means \"a categorical variable with LOTS of values\". [See this discussion.](https://aeturrell.github.io/coding-for-economists/econmt-regression.html#high-dimensional-fixed-effects-aka-absorbing-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: Summarize what you've learned so far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: Plot the regression\n",
    "\n",
    "_If time is tight: I'll do it._\n",
    "\n",
    "Plot 1:\n",
    "- Plot a scatterplot: Plot as X the credit score variable. As Y, use our y.\n",
    "- On top of that, lineplots:\n",
    "    - Rerun Q1a's reg and plot the yhat values. \n",
    "    - Let's talk about this.\n",
    "    - Rerun Q1b's reg and plot the yhat values.\n",
    "    - Compare to the prior line.\n",
    "    \n",
    "Plot 2:\n",
    "- Plot a scatterplot: Plot as X the credit score variable. As Y, use our y.\n",
    "- On top of that, lineplots:\n",
    "    - Rerun Q4b's reg and plot the yhat values, hued by credit bin\n",
    "  \n",
    "Plot 3:\n",
    "- Plot a scatterplot: Plot as X the credit score variable. As Y, use our y.\n",
    "- On top of that, lineplots:\n",
    "    - Rerun Q4b's reg BUT WITH credit score as a variable and plot the yhat values, hued by credit bin  \n",
    "    \n",
    "_Note: statsmodels has some useful plotting functions. My favs are influence_plot (can be slow) and plot_partregress_grid._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with SKLEARN\n",
    "\n",
    "I don't like running regressions in `sklearn` usually. The main reason to do so is if you're doing a typical ML task that sklearn excels in (meaning: \"pipelines\", which is a term you'll understand later in the course) or if you know you're going to be using other sklearn models anyways (in which case, you'll already be doing the set up for sklearn).\n",
    "\n",
    "But I want to run at least one regression in SKLEARN for you so you can see how the mechanics are similar, and how they differ. We will cover sklearn more in future classes.\n",
    "\n",
    "Psuedocode for a reg in sklearn is similar. The differences:\n",
    "1. A little more work setting up the data\n",
    "1. `.fit()` gets the data passed to it \n",
    "1. The `results` object is different than statsmodels'\n",
    "\n",
    "```python\n",
    "\n",
    "# 1. import the \"class\" of model form sklearn\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 2. arrange the data - more work than statsmodels\n",
    "\n",
    "# Issue: sklearn doesn't work with missing values, so drop any obs with missing values\n",
    "# replace vars_in_your_reg with a list of variables you want to use, including y\n",
    "subset = df[vars_in_your_reg].dropna()\n",
    "\n",
    "# explicitly set up the y variable and the X variables you want\n",
    "y = subset['y'] # whatever the y variable is\n",
    "X = subset[['X1','X2']] # list the X vars\n",
    "\n",
    "# 3. set up the model (\"instantiate the model\")\n",
    "# every class of models has \"hyperparamaters\" that control how you want the model to work\n",
    "# below, fit_intercept=True is a \"hyperparameter\" for OLS models \n",
    "# hyperparameters are the things inside the parenthesis of the model class when you declare it\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "result=model.fit(X,y) # in sklearn, you put X and Y inside fit!!!\n",
    "\n",
    "# the result object is different in sklearn\n",
    "# results.intercept_ (the constant in the model)\n",
    "# results.coef_ (the other X vars)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: STUDENT DEMO - regressions **using sklearn**\n",
    "\n",
    "A. Regress the interest rate on the natural log of the loan-to-value using the sklearn method.\n",
    "\n",
    "B. Regress the interest rate on the natural log of the loan-to-value using the sklearn method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
